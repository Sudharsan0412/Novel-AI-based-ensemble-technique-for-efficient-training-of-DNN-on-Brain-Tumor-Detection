{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9408599,"sourceType":"datasetVersion","datasetId":5712845}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom PIL import Image\nimport copy\nimport time\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:26:44.408422Z","iopub.execute_input":"2025-02-16T16:26:44.408700Z","iopub.status.idle":"2025-02-16T16:26:52.422192Z","shell.execute_reply.started":"2025-02-16T16:26:44.408678Z","shell.execute_reply":"2025-02-16T16:26:52.421370Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Device configuration","metadata":{}},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Using device: {device}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:27:27.319519Z","iopub.execute_input":"2025-02-16T16:27:27.320020Z","iopub.status.idle":"2025-02-16T16:27:27.374231Z","shell.execute_reply.started":"2025-02-16T16:27:27.319991Z","shell.execute_reply":"2025-02-16T16:27:27.373426Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Data Augmentation using Albumentations","metadata":{}},{"cell_type":"code","source":"# Data augmentation using Albumentations\ndata_transforms = {\n    'train': A.Compose([\n        A.Resize(224, 224),\n        A.RandomCrop(224, 224),\n        A.HorizontalFlip(),\n        A.RandomBrightnessContrast(),\n        A.Rotate(limit=15),\n        A.CoarseDropout(max_holes=1, max_height=16, max_width=16, fill_value=0, mask_fill_value=None),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ]),\n    'val': A.Compose([\n        A.Resize(224, 224),\n        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n        ToTensorV2(),\n    ])\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:29:59.058460Z","iopub.execute_input":"2025-02-16T16:29:59.058788Z","iopub.status.idle":"2025-02-16T16:29:59.068646Z","shell.execute_reply.started":"2025-02-16T16:29:59.058765Z","shell.execute_reply":"2025-02-16T16:29:59.067950Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Custom dataset loader","metadata":{}},{"cell_type":"code","source":"# Custom Dataset Loader\nclass CustomImageDataset(datasets.ImageFolder):\n    def __init__(self, root, transform=None):\n        super(CustomImageDataset, self).__init__(root, transform=None)\n        self.custom_transform = transform\n\n    def __getitem__(self, index):\n        image, label = super(CustomImageDataset, self).__getitem__(index)\n        image = np.array(image)\n        if self.custom_transform:\n            augmented = self.custom_transform(image=image)\n            image = augmented['image']\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:30:45.773665Z","iopub.execute_input":"2025-02-16T16:30:45.774016Z","iopub.status.idle":"2025-02-16T16:30:45.779011Z","shell.execute_reply.started":"2025-02-16T16:30:45.773987Z","shell.execute_reply":"2025-02-16T16:30:45.778069Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Dataset loading and splitting","metadata":{}},{"cell_type":"code","source":"# Dataset Loading and Splitting\ndata_dir = '/kaggle/input/brain-tumor-mri-scans'\nfull_dataset = CustomImageDataset(data_dir, transform=data_transforms['train'])\n\ntrain_size = int(0.7 * len(full_dataset))\nval_size = int(0.15 * len(full_dataset))\ntest_size = len(full_dataset) - train_size - val_size\ntrain_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n\nval_dataset.dataset.custom_transform = data_transforms['val']\ntest_dataset.dataset.custom_transform = data_transforms['val']\n\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:32:12.475391Z","iopub.execute_input":"2025-02-16T16:32:12.475689Z","iopub.status.idle":"2025-02-16T16:32:17.566215Z","shell.execute_reply.started":"2025-02-16T16:32:12.475667Z","shell.execute_reply":"2025-02-16T16:32:17.565539Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Model Architecture (ResNet50)","metadata":{}},{"cell_type":"code","source":"# Model Architecture (ResNet50)\nmodel = models.resnet50(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 4)  # 4 classes\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:33:01.871696Z","iopub.execute_input":"2025-02-16T16:33:01.872048Z","iopub.status.idle":"2025-02-16T16:33:03.196894Z","shell.execute_reply.started":"2025-02-16T16:33:01.872022Z","shell.execute_reply":"2025-02-16T16:33:03.196005Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 201MB/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Loss function and optimizer","metadata":{}},{"cell_type":"code","source":"# Loss Function and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:33:43.586679Z","iopub.execute_input":"2025-02-16T16:33:43.587024Z","iopub.status.idle":"2025-02-16T16:33:43.591633Z","shell.execute_reply.started":"2025-02-16T16:33:43.586996Z","shell.execute_reply":"2025-02-16T16:33:43.590814Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Training and evaluation function","metadata":{}},{"cell_type":"code","source":"# Training and Evaluation Functions\ndef train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=25):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n    \n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        model.train() \n        running_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        val_loss, val_acc = evaluate_model(model, val_loader, criterion)\n        scheduler.step(val_loss)\n        \n        print(f\"Train Loss: {running_loss/len(train_loader)}, Val Loss: {val_loss}, Val Acc: {val_acc}\")\n        history['train_loss'].append(running_loss/len(train_loader))\n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n\n    model.load_state_dict(best_model_wts)\n    return model, history\n\ndef evaluate_model(model, data_loader, criterion):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    return running_loss / len(data_loader), 100 * correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:36:54.027733Z","iopub.execute_input":"2025-02-16T16:36:54.028081Z","iopub.status.idle":"2025-02-16T16:36:54.036026Z","shell.execute_reply.started":"2025-02-16T16:36:54.028056Z","shell.execute_reply":"2025-02-16T16:36:54.035193Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"# Train the Model\nnum_epochs = 25\nmodel, history = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T16:37:01.443103Z","iopub.execute_input":"2025-02-16T16:37:01.443606Z","iopub.status.idle":"2025-02-16T16:56:44.698480Z","shell.execute_reply.started":"2025-02-16T16:37:01.443576Z","shell.execute_reply":"2025-02-16T16:56:44.697596Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/25\nTrain Loss: 0.41799333749653456, Val Loss: 0.988078155300834, Val Acc: 75.97340930674264\nEpoch 2/25\nTrain Loss: 0.2249378642285025, Val Loss: 0.7920416620644656, Val Acc: 78.15764482431149\nEpoch 3/25\nTrain Loss: 0.18438051872003774, Val Loss: 0.45953428654959705, Val Acc: 82.81101614434948\nEpoch 4/25\nTrain Loss: 0.13456804447432424, Val Loss: 0.45327305342211865, Val Acc: 85.75498575498575\nEpoch 5/25\nTrain Loss: 0.10170559770149457, Val Loss: 0.38426568697799335, Val Acc: 86.8945868945869\nEpoch 6/25\nTrain Loss: 0.08327103117420398, Val Loss: 0.15562825068605668, Val Acc: 95.25166191832858\nEpoch 7/25\nTrain Loss: 0.08199630007782782, Val Loss: 0.6327006762677972, Val Acc: 83.38081671415004\nEpoch 8/25\nTrain Loss: 0.0935684459967321, Val Loss: 1.4165346333474824, Val Acc: 69.8005698005698\nEpoch 9/25\nTrain Loss: 0.06716587620654277, Val Loss: 0.1790808696074016, Val Acc: 94.87179487179488\nEpoch 10/25\nTrain Loss: 0.053180321948995884, Val Loss: 1.978997078808871, Val Acc: 67.80626780626781\nEpoch 11/25\nTrain Loss: 0.038064118128405225, Val Loss: 0.12272566012953492, Val Acc: 96.77113010446344\nEpoch 12/25\nTrain Loss: 0.0478433324201728, Val Loss: 0.1307059980392682, Val Acc: 95.82146248812916\nEpoch 13/25\nTrain Loss: 0.05600601398157766, Val Loss: 0.5383756232984138, Val Acc: 86.70465337132003\nEpoch 14/25\nTrain Loss: 0.05243504605998358, Val Loss: 0.225020568803743, Val Acc: 94.20702754036087\nEpoch 15/25\nTrain Loss: 0.046705070304360795, Val Loss: 0.20471714643027747, Val Acc: 94.77682811016145\nEpoch 16/25\nTrain Loss: 0.037742124866072826, Val Loss: 0.397841378538446, Val Acc: 90.21842355175689\nEpoch 17/25\nTrain Loss: 0.04054903207129841, Val Loss: 0.18190887997942892, Val Acc: 95.53656220322887\nEpoch 18/25\nTrain Loss: 0.013015091136213568, Val Loss: 0.0786064743667587, Val Acc: 98.10066476733144\nEpoch 19/25\nTrain Loss: 0.005235064603435934, Val Loss: 0.07621439234141937, Val Acc: 98.2905982905983\nEpoch 20/25\nTrain Loss: 0.004606014995060123, Val Loss: 0.08124012446602467, Val Acc: 98.2905982905983\nEpoch 21/25\nTrain Loss: 0.002440258133134052, Val Loss: 0.07479543893802629, Val Acc: 98.48053181386514\nEpoch 22/25\nTrain Loss: 0.0023116234005774697, Val Loss: 0.09384063835199358, Val Acc: 97.81576448243115\nEpoch 23/25\nTrain Loss: 0.0015779677293969805, Val Loss: 0.07324607140441058, Val Acc: 98.57549857549857\nEpoch 24/25\nTrain Loss: 0.0017713800124711978, Val Loss: 0.07665704717422187, Val Acc: 98.57549857549857\nEpoch 25/25\nTrain Loss: 0.0012672593831973848, Val Loss: 0.08206068918772155, Val Acc: 98.2905982905983\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"code","source":"# Save the Model\ntorch.save(model.state_dict(), 'brain_tumor_resnet50.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T17:02:17.010541Z","iopub.execute_input":"2025-02-16T17:02:17.010895Z","iopub.status.idle":"2025-02-16T17:02:17.156585Z","shell.execute_reply.started":"2025-02-16T17:02:17.010864Z","shell.execute_reply":"2025-02-16T17:02:17.155565Z"}},"outputs":[],"execution_count":15}]}